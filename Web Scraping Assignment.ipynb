{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f5853d-2f47-4d7e-9914-018c47a8aef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Q1. What is Web Scraping? Why is it Used? Give three areas where Web Scraping is used to get data.'''\n",
    "\n",
    "'''Web scraping is a process of extracting data or information from websites .\n",
    "\n",
    "it is used to extract data or sequence of data from websites which is not feasible to do manually.\n",
    "\n",
    "three areas where web scarping is used to get data are -\n",
    "\n",
    "1.for analysisng a big data .\n",
    "2.for comparing same data of many people .\n",
    "3.for extracting required information from a very big data .'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d5e22d-ad7a-422f-902f-db4d0b2b14a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Q2. What are the different methods used for Web Scraping?'''\n",
    "\n",
    "there are several methods used for web scraping like -\n",
    "\n",
    "1. Manual Scraping - by copying from url and storing it into a local file \n",
    "\n",
    "2. By using browser tools ( Clicking on F12 and Extracting data from website ).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bddc73d-da22-46e4-bfd8-2f27eb370407",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Q3. What is Beautiful Soup? Why is it used?'''\n",
    "\n",
    "'''Beautiful Soup is a tool which we import from bs4 .\n",
    "\n",
    "BeautifulSoup is used to beautify the html content of the url page which we are trying to scrap .\n",
    "by applying beautiful soup , the html content of the url page get sorted like it get some indentation and\n",
    "get a proper format.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d3ed95-3aa7-4557-b036-f8eefd38f009",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Q4. Why is flask used in this Web Scraping project?'''\n",
    "\n",
    "'''We use flask for web scrapping project because flask is used to create web applications which uses web api protocols\n",
    "   which we need for our web scraping project.\n",
    "\n",
    "it also provides us many facilities. the facilities are as follows :-\n",
    "\n",
    "1. We can push the code to github very easily from here.\n",
    "\n",
    "2. it provides the proper folder format in which we can keep the essential files required for project like\n",
    "   index.html , requirements.txt,etc.\n",
    "   '''\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f5b1ce-aac3-4473-ace4-025b572c3448",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Q5. Write the names of AWS services used in this project. Also, explain the use of each service.'''\n",
    "\n",
    "'''The AWS services used in the project are \n",
    "1. code pipeline - it helps to join the github repository where the project is saved with the beanstack . so it's basically \n",
    "   a pipeline which is connecting the project which is present in github with the beanstack .\n",
    "2.beanstack -  it is a program where the project gets deployed .If everything goes right it provides the url \n",
    "   from where we can run our project in the AWS '''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
